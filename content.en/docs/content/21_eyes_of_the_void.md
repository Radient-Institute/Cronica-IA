---
weight: 21
bookFlatSection: true
title: "21 – Eyes of the Void"
image: _din_style/banner_images/21_lodv.webp
---

# Eyes of the Void

## The impact of AI on science

It’s hard to quantify the impact AI has had on science, especially when one isn’t an expert in every discipline it has touched. But if there is one inflection point recognized across the entire scientific community, it is **AlphaFold 2**: DeepMind’s model that, in 2020, demonstrated it could predict the three-dimensional structure of proteins from their amino acid sequence with accuracy high enough that the historic protein-folding problem could be considered essentially solved.

The specific downstream impact of this technology—for example, which concrete drugs it has enabled—goes beyond my area of expertise, but its importance is indisputable. Its scientific publication has accumulated close to **40,000 citations** and has received the most prestigious scientific recognition in the world.

In October 2024, something unexpected happened. The Royal Swedish Academy of Sciences awarded **two Nobel Prizes** related to advances in artificial intelligence.  
The first, in **Physics**, went to **John Hopfield** and **Geoffrey Hinton** for the invention of Hopfield networks and Boltzmann machines. The decision was widely criticized: many felt these advances had little direct relevance to physics and only limited impact on modern AI.  

The second Nobel, in **Chemistry**, went to **David Baker**, **Demis Hassabis**, and **John Jumper** for their work on protein design and structure prediction. Here, by contrast, there was broad consensus: AlphaFold had transformed structural biology.

Below are some of the most relevant AI models applied to science since then. All of them were trained to solve specific tasks; they are not general models:

- **AlphaFold 3** (DeepMind, May 2024): extends structural prediction to DNA, RNA, ligands, and molecular complexes.  
- **AlphaChip** (DeepMind, September 2024): designs chips by automatically optimizing performance and area.  
- **MatterGen** (Microsoft, January 2025): a generative model that proposes new crystalline materials conditioned on desired properties.  
- **Metagene** (Metagene.ai, January 2025): a foundational model for global genomic surveillance using environmental DNA.  
- **AlphaEvolve** (DeepMind, May 2025): an agent that discovers new algorithms via evolution and automated evaluation.  
- **Chai-2** (Chai Discovery, June 2025): a system that designs antibodies entirely from scratch with a high success rate.  
- **AlphaEarth** (DeepMind, August 2025): a geospatial model that acts as a “virtual satellite” to monitor the planet.  
- **GPT-4b micro** (OpenAI, August 2025): a biological model for protein design and longevity research.

## The first steps toward superintelligence?

There is broad agreement that the highest expression of human intelligence manifests in science. We don’t usually think the smartest person in the world is a comedian or a political pundit, but rather a physicist, a mathematician, a scientist: Newton, Einstein, and so on.

For that reason, when we talk about *super*-intelligence, we tend to assume it must prove itself by surpassing the best humans in the tasks we consider most intellectually demanding.

During the second half of 2025, OpenAI launched a campaign to demonstrate exactly that: that its models possessed capabilities comparable to—or even exceeding—those of the best humans in formally difficult disciplines. They took several experimental models and entered them into real competitions.

The first was the **IMO**, the International Mathematical Olympiad (high-school level). Their experimental model achieved a gold medal. (Google also won gold that year.)

The second was the **IOI**, the International Olympiad in Informatics (university level). Once again, OpenAI’s model won a gold medal. (Google repeated the feat.)

The third had no age limit: **AtCoder**, in the heuristics category—one of the most demanding programming competitions in the world. OpenAI’s experimental model achieved **second place**, losing by a very small margin to the best human participant… who, coincidentally, was a former OpenAI employee.

These results generated great surprise on one side and significant criticism on the other. The methodology is not public: we don’t know how much humans intervene through *prompting*, answer selection, how many samples are generated, or how many *tokens* are consumed. In the end, no one audits OpenAI, and the company is not transparent about the details behind these achievements. But even if many use these arguments to downplay their importance, it’s hard to deny that the overall vibe strongly echoes **Kasparov vs. Deep Blue**.

In parallel, several *startups* announced that their agents had achieved previously unknown mathematical discoveries. **Math Inc** claimed to have solved the *Terry Tao & Alex Kontorovich Strong Prime Number Theorem* in just three weeks. It was also announced that Erdős problem **#339** had been solved by ChatGPT Pro, and **#124** by *Aristotle*, another specialized agent.
