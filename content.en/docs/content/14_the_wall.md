---
weight: 14
bookFlatSection: true
title: "14 – The Wall"
image: _din_style/banner_images/14_em.webp
---

# The Wall

The scaling laws, popularized by an OpenAI paper, planted a simple idea in many minds: the more you scale your model (in parameters, data, or compute), the better its performance will be—and that this improvement can be roughly estimated in logarithmic terms. From this emerged a phrase repeated by CEOs and *researchers*: **“intelligence is the logarithm of compute.”**

Sometime in November 2024, headlines and interviews began circulating about the existence of a “wall” in AI—the idea that model capabilities had reached a limit. This is somewhat strange, because it’s not entirely clear what event triggered this discussion. Perhaps the prolonged absence of GPT-5 contributed, or the feeling—months after using O1—that it wasn’t as revolutionary as had been implied. Or maybe it was seeing a model stop jumping from 50 to 92 on a benchmark and instead inch from 92 to 96.

Either way, the debate opened up. Had AI (or more precisely, LLMs) hit a wall?  
Soon, the discussion shifted to something more concrete: the possibility that scaling laws were no longer as favorable. Scaling a model 10× beyond the current state of the art is no longer simple—or “cheap”—and the marginal improvement may not justify the cost, especially if the market isn’t willing to pay more than $100 per million tokens.

To be fair, since the term “wall” first appeared, there have been advances in absolutely every area of AI. Today, the word is no longer commonly used to claim that “progress has stopped,” but rather to describe **the diminishing returns of traditional scaling** under current compute and energy constraints.

This was exemplified in March 2025 with the release of **GPT-4.5**, known internally at OpenAI as *Orion*. According to rumors, it was supposed to be GPT-5 due to the scale jump—but its performance wasn’t surprising enough, and its cost was too high. It ended up being renamed GPT-4.5 and was deprecated a few months later. It wasn’t a bad model—in fact, it was excellent at writing and likely served as a base for distilling smaller versions. But its slowness, and the fact that it wasn’t a reasoning model, pushed it aside.

With this, the unwritten rule was broken: that a numerical jump in the GPT series represented a clear leap in scale and capability. And with the parallel existence of the O saga (reasoning models), it was no longer clear what GPT-5 would mean when it arrived—or how it would fit alongside the other model lines. OpenAI then pointed toward a new concept: **unified intelligence**. A single model that would integrate everything—Deep Research, the image model, the audio model, the reasoner, the agents, and the “normal” GPT—all into one intelligence.

The release of GPT-5 in August 2025 was heavily hyped by OpenAI employees. And it ended up being a disappointment. They promised something mind-blowing and delivered a model that was “a bit better.” Yes, it was number one at the time—but without a dominant lead. To make matters worse, the router between the thinking and non-thinking versions failed during the first few days.

Criticism multiplied. Conversations about “the wall” resurfaced and continue to reappear whenever a launch promises too much and delivers too little.

As for the unified intelligence plan, that didn’t fully work either. Pressure from ChatGPT users forced OpenAI to keep a selector between thinking and non-thinking modes and to bring back the deprecated GPT-4o. Full unification will have to wait.
