---
weight: 14
bookFlatSection: true
title: "14 - El Muro"
image: _din_style/banner_images/14_em.webp
---

# El Muro

Las leyes de escala, popularizadas por un paper de OpenAI, instalaron en la mente de muchos una idea sencilla: mientras más escales tu modelo (en parámetros, datos o cómputo), mejor será su rendimiento. Y que esa mejora puede estimarse aproximadamente de forma logarítmica. De ahí nació la frase, repetida por CEOs y *researchers*: **“la inteligencia es el logaritmo del cómputo”**.

En algún punto de noviembre del 2024 comenzaron a circular titulares y entrevistas mencionando la existencia de un “muro” en la IA: la idea de que las capacidades de los modelos habían alcanzado un límite. Esto es algo raro, porque no tengo del todo claro que suceso desencadenó esta discusión. Tal vez contribuyó la ausencia prolongada de GPT-5, o la sensación, meses después de usar O1, de que no era tan revolucionario como se insinuó. O quizás influyó ver que un modelo dejaba de subir de 50 a 92 en un benchmark, y empezaba a subir solo de 92 a 96.

Sea como sea, el debate se abrió. ¿Habían chocado la IA (o mas precisamente los LLMs) con un muro?  
Al poco tiempo la discusión derivó en algo más concreto: la posibilidad de que las leyes de escala ya no fueran tan favorables. Escalar un modelo 10 veces más que el estado del arte actual ya no es tan sencillo, ni tan "barato", y la mejora marginal podría no compensar el costo, especialmente si el mercado no está dispuesto a pagar más de 100 dólares por millón de tokens.

Para ser justos, desde que apareció el término “muro”, ha habido avances en absolutamente todas las áreas de la IA. Hoy en día la palabra ya no suele usarse para afirmar que “el avance se detuvo”, sino para describir **los rendimientos decrecientes del escalado tradicional** bajo las limitaciones actuales de cómputo y energía.

Esto quedó ejemplificado en marzo del 2025 con la salida de **GPT-4.5**, conocido internamente en OpenAI como *Orion*. Según rumores, debía ser GPT-5 debido al salto en escala, pero su rendimiento no sorprendió lo suficiente y su costo era demasiado alto. Terminó siendo renombrado como GPT-4.5 y fue deprecado unos meses después. No era un mal modelo, de hecho, era excelente escribiendo, y seguramente sirvió como base para destilar versiones más pequeñas. Pero su lentitud y el hecho de no ser una versión de razonamiento lo relegaron.

Con esto se rompió la regla no escrita, de que un salto numérico en la serie GPT representaba un salto claro en escala y capacidad. Y con la existencia paralela de la saga O (los modelos de razonamiento), tampoco quedaba claro qué significaría GPT-5 cuando llegara, ni cómo encajaría con las demás líneas de modelos. OpenAI apuntó entonces a un concepto nuevo: **la inteligencia unificada**. Un solo modelo que integrara todo: Deep Research, el modelo de imágenes, el de audio, el razonador, los agentes, y el GPT “normal"; todo en una sola inteligencia.

La salida de GPT-5 en agosto del 2025 fue intensamente promocionada por los empleados de OpenAI. Y terminó siendo una decepción. Prometieron algo alucinante y entregaron un modelo “un poco mejor”. Sí, era el número uno del momento, pero no con una ventaja dominante. Para empeorar las cosas, el enrutador entre la versión thinking y la non-thinking falló durante los primeros días.

Las críticas se multiplicaron. Las conversaciones sobre “el muro” reaparecieron y siguen resurgiendo cada vez que un lanzamiento promete demasiado y cumple poco.

En cuanto al plan de la inteligencia unificada, tampoco funcionó del todo. La presión de los usuarios de ChatGPT obligó a mantener un selector entre thinking y non-thinking y a traer de vuelta al deprecado GPT-4o. La unificación completa tendrá que esperar.
