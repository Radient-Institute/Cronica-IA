---
weight: 21
bookFlatSection: true
title: "21 - Ojos del Vacío"
image: _din_style/banner_images/21_lodv.webp
---

# Ojos del Vacío

## El impacto de la IA en la ciencia

Es difícil cuantificar el impacto que la IA ha tenido en la ciencia, especialmente cuando uno no es experto en todas las disciplinas que esta ha tocado. Pero si hay un punto de inflexión reconocido por toda la comunidad científica, es **AlphaFold 2**: el modelo de DeepMind que, en 2020, demostró que podía predecir la estructura tridimensional de proteínas en función de su secuencia de aminoácidos con una precisión lo suficientemente alta como para considerar el histórico problema del plegado de proteínas como esencialmente resuelto.

El impacto específico de esta tecnología, por ejemplo, qué medicamentos concretos ha permitido desarrollar, va más allá de mi área, pero es indiscutible. Su publicación científica acumula cerca de 40.000 citaciones y ha recibido el reconocimiento científico más prestigioso del mundo.

En octubre del 2024 ocurrió algo inesperado. La Real Academia Sueca de las Ciencias otorgó **dos Premios Nobel** relacionados con avances en inteligencia artificial.  
El primero, en **Física**, fue otorgado a **John Hopfield** y **Geoffrey Hinton** por la invención de las redes de Hopfield y las máquinas de Boltzmann. La decisión fue ampliamente criticada: muchos consideraron que estos avances tenían poca relevancia directa para la física y también un impacto limitado en la IA moderna.  

El segundo Nobel, en **Química**, fue para **David Baker**, **Demis Hassabis** y **John Jumper** por su trabajo en el diseño de proteínas y en la predicción de su estructura. Aquí, en cambio, hubo consenso: AlphaFold había transformado la biología estructural.

A continuación, algunos de los modelos más relevantes de IA aplicada a la ciencia desde entonces. Todos ellos fueron entrenados para resolver tareas específicas; no son modelos generales:

- **AlphaFold 3** (DeepMind, mayo 2024): amplía la predicción estructural a ADN, ARN, ligandos y complejos moleculares.
- **AlphaChip** (DeepMind, septiembre 2024): diseña chips optimizando rendimiento y área de forma automática.
- **MatterGen** (Microsoft, enero 2025): modelo generativo que propone nuevos materiales cristalinos condicionados a propiedades.
- **Metagene** (Metagene.ai, enero 2025): modelo fundacional para vigilancia genómica global usando ADN ambiental.
- **AlphaEvolve** (DeepMind, mayo 2025): agente que descubre nuevos algoritmos mediante evolución y evaluación automática.
- **Chai-2** (Chai Discovery, junio 2025): sistema que diseña anticuerpos totalmente de cero con alta tasa de éxito.
- **AlphaEarth** (DeepMind, agosto 2025): modelo geoespacial que actúa como “satélite virtual” para monitorizar el planeta.
- **GPT-4b micro** (OpenAI, agosto 2025): modelo biológico para diseño de proteínas e investigación en longevidad.

## ¿Los primeros pasos de la superinteligencia?

Existe un consenso general en que la expresión máxima de la inteligencia humana se manifiesta en la ciencia. No solemos pensar que la persona más inteligente del mundo sea un comediante o un politólogo, sino un físico, un matemático, un científico: Newton, Einstein, etc.

Por eso, cuando hablamos de *super*-inteligencia, tendemos a asumir que debe demostrarse superando a los mejores humanos en las tareas que consideramos más intelectualmente demandantes.

Durante la segunda mitad del 2025, OpenAI inició una cruzada para demostrar precisamente eso: que sus modelos poseían capacidades comparables (o incluso superiores) a las de los mejores humanos en disciplinas formalmente difíciles. Tomaron varios modelos experimentales y los inscribieron en competencias reales.

La primera fue la **IMO**, la Olimpiada Internacional de Matemáticas (nivel secundaria). Su modelo experimental logró una medalla de oro. (Google también obtuvo oro ese año).

La segunda fue la **IOI**, la Olimpiada Internacional de Informática (nivel universitario). Nuevamente, el modelo de OpenAI obtuvo una medalla de oro. (Google repitió la hazaña).

La tercera ya no tenía límite de edad: participaron en **AtCoder**, en la categoría de heurísticas, una de las competencias de programación más exigentes del mundo. El modelo experimental de OpenAI consiguió **el segundo puesto**, perdiendo por muy poco frente al mejor participante humano… quien, casualmente, era un exempleado de OpenAI.

Estos resultados generaron mucha sorpresa por un lado y muchas críticas por otro. La metodología no es pública: no sabemos cuánto intervienen los humanos mediante *prompting*, selección de respuestas, cuántas muestras generan, cuántos *tokens* consumen. Al final, nadie fiscaliza a OpenAI, y la empresa no es transparente respecto a los detalles detrás de estos logros. Pero a pesar que muchos usen estos argumentos para cuestionar la importancia de estos logros, no se puede negar que la vibra general recuerda a **Kasparov vs DeepBlue**.

En paralelo, varias *startups* anunciaron que sus agentes habían logrado descubrimientos matemáticos inéditos. La empresa **Math Inc** afirmó haber resuelto el *Terry Tao & Alex Kontorovich’s Strong Prime Number Theorem* en solo tres semanas. También se anunció la resolución del problema de Erdős **#339** por ChatGPT Pro, y del **#124** por *Aristotle*, otro agente especializado.

